

## Lecture 11: ConvNets in practice

https://www.youtube.com/watch?v=pA4BsUK3oP4


* data augmentation
  * shift pixels slightly, don't change label
  * horizontal flips
  * color jitter (pca jitter is more common)
  * random crops
  * increases size of training set for free!
  * at test time, do multiple crops and average scores for each crop
* transfer learning
  * take already trained model, freeze it and treat it as a feature extractor (add single layer on top or something)
  * finetuning - train top few layers 
  * what to do
    * similar dataset + little data: linear classifier on top layer
    * similar data + lots of data: fintune a few layers
    * different data + little data: linear classifer from different stages (trouble)
    * diff data + lots data: finetune lots of layers
* how to stack convolutions
  * 1 3z3 has the same power as a 7x7 convolution, but fewer parameters and MORE nonlinearity
  * ===> multiple small filters might be better
  * people have taken this to the extreme, using 1x1 "bottleneck" filters that help you save a lot on parameters
* implementing convolutions
  * im2col: easy to implement, matrix muls, big memory overheat
  * fft is a cool idea but hard to do in practice
* implementation details (CPU vs GPU)
  * cpu: few fast cores
  * gpu: many slow cores
    * people often split minibatches across gpu's
    * tensorflow does best distributions automatically
* bottlenecks you should be aware of
  * most expensive step: copying data on and off gpu
  * store data in contiguous files. if you use multiple files, you have to do disk seeks as you're reading in examples
  * gpu memory can also be a bottleneck. titan x has 12GB, which is current max
* floating point percision
  * 32 bit "single" percisiosn is popular 
    * speedups
  * 16 bit is also a thing ("half" precision). fewer bits, faster to compute. also some evidence it acts like a regularizer
    * but have trouble converging (precision errors add up)
    * soln: cast up for multiplications, stochastically round back down (randomly select landing point probabilistically)





