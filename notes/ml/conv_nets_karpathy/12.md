## Deep Learning libraries

https://www.youtube.com/watch?v=Vf_-OkqbwPo


* caffe, torch, theano, tensorflow
* **caffe**
  * from berkeley
  * written in c++
  * came out of a reimplementation of alexnet
  * major classes
    * **blob**: stores weights + activations 
      * paralell tensors for data and their derivatives
    * **layer**: computations on blbs
    * **net**: combines a bunch of layers
    * **solver**: use gradients to update weights (sgd, adam, etc)
  * makes use of **protocol buffers**
    * binary json-like thing
  * don't need to write code!
    * convert data (to LMDB)
    * define model AND solver with procol buf
    * train model by running a script
  * has a great model zoo if you want resnet, alexnet, etc
  * python interface too
  * MINUS: need to write your own c++/CUDE for new GPU layers
* **torch**
  * from nyu
  * used at fb, deepmind
  * have to write it in lua, similar to javascript
  * everything in lua is 1-indexed!!
  * uses tensors, just like numpy array. except they're stored on the GPU, which is awesome
  * to run on the gpu, just need to cast everything as the gpu-stored datatype
  * use `optim` package for training (adam, momentum, etc)
  * very easy to implement your own new modules
    * only need to implement forward, backward pass
    * can put anything you want in there (forward, backward pass, etc)    
  * can load pretrained caffe models (that's cool)
  * not great for RNNs!
* **theano**
  * from bengio's group at montreal
  * all about computational graphs
  * theano computes gradients for you automatically (grad of any part of the graph w/r/t any other part..that's cool)
  * problem: CPU and GPU comunicate a lot. sidestepped with "shared variables"
    * provide update rules that can be applied repeatidly. then eveything is done on the GPU
  * **lasagne**
    * high-level theano wrapper that can write update rules for you
  * **keras**
    * another SUPER high level wrapper
    * does everything for you
* **tensorflow**
  * shiney and new, from google
  * similar to theano (structured as graph)
  * tensorboard is pretty cool too
  * can intellegently distribute computations across GPU's and graphs
  * not many pre-trained models... :(




