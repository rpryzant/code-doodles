## Segmentation, soft attention, spatial transformers

https://www.youtube.com/watch?v=ByjaPdWXKJ4


* **segmentation**
  * semantic semengation
    * description
      * take image, find instances, don't differentiate instances
      * label each pixel with semantic class
    * method
      * extract patches, classify center pixel
      * repeat for every pixel
      * this is slow, so in practice they use convolutions to get all pixels at once
    * people often do multiple scalings 
    * also iterative segmentation: re-feed outputs into conv net
    * skip connections from lower layers also helps 
  * instance segmentation
    * label each pixel with class AND instance info
    * method
      * propose segments with seperate thing	
      * mask out background with a mean image
      * extract features with cnn, then classify the class, then refine proposed region
      * refinement
      	* classifer that predicts whether pixels are in foreground or backgraound
	* skip connections from early and late layers
* deconvolutions
  * take filter, copy over to output (reverse stride, conv)
  * just add where regions overlap
  * just like normal convolution backward pass
  * **upconvolution** or **convolution transpose** is more technically correct
* **attention models**
  * very cool. image captioning example
  * hard vs soft attention
    * soft: averaging over all positions, not as efficient. distribution over input
    * hard: attend to single input location. non-differentiable, so can't use sgd
  * need RL for hard
  * attention came out of machine translation 







