{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "import purestemmer as Stemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('protein', 8), ('dna', 7), ('cell', 6), ('ribosom', 6), ('acid', 4)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean(w):\n",
    "    w = w.translate(None, string.punctuation).lower()\n",
    "    stemmer = Stemmer.Stemmer('english')\n",
    "    return stemmer.stemWord(w.lower())\n",
    "\n",
    "\n",
    "def parse_stop(f):\n",
    "    return set([clean(x.strip()) for x in open(f).readlines()])\n",
    "\n",
    "def clean_sentence(s, stop_words):\n",
    "    stemmer = Stemmer.Stemmer('english')\n",
    "    return [clean(w) for w in s.split() \\\n",
    "            if clean(w) not in stop_words]\n",
    "\n",
    "def flatten(l):\n",
    "    \"\"\" flattens a list of lists \"\"\"\n",
    "    return [w for s in l for w in s]\n",
    "\n",
    "def word_freqs(doc, nested=False):\n",
    "    return Counter(flatten(doc) if nested else doc)\n",
    "\n",
    "def rm_words(doc, words):\n",
    "    return [[w for w in s if w not in words] \\\n",
    "             for s in doc]\n",
    "\n",
    "def score(sentence, pivots):\n",
    "    return sum([pivots.get(w, 0) for w in sentence])\n",
    "\n",
    "\n",
    "K = 5\n",
    "N = 5\n",
    "\n",
    "input = 'example.txt'\n",
    "stops = 'stop_words.txt'\n",
    "\n",
    "stop_words = parse_stop(stops)\n",
    "raw_doc = sent_tokenize(open(input).read())\n",
    "doc = map(lambda s: clean_sentence(s, stop_words), raw_doc)\n",
    "\n",
    "pivots = word_freqs(doc, nested=True).most_common(K)\n",
    "\n",
    "print pivots\n",
    "\n",
    "\n",
    "scores = map(lambda x: score(x, dict(pivot_words)), doc)\n",
    "top_sentences = sorted(zip(scores, range(len(scores))), reverse=True)[:N]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    input = sys.argv[1]\n",
    "    \n",
    "    summarizer = Summarizer(input)\n",
    "    \n",
    "    print summarizer.summarize(n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
